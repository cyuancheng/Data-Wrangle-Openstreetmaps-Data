{
 "metadata": {
  "name": "",
  "signature": "sha256:ee2d741ebaf07e8af393f2142ecf6f6e7d31170b37fe24f873765df2a0b14c39"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Analyzing OpenstreetMap Data | Data Wrangling with MongoDB\n",
      "- Author:  Chi-Yuan Cheng (cyuancheng AT gmail DOT com) \n",
      "- Last updated: May 1th  2015"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Map Area: Santa Barbara County, CA, United States\n",
      "\n",
      "The data set can be found here: https://s3.amazonaws.com/metro-extracts.mapzen.com/santa-barbara_california.osm.bz2 "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "OSM_FILE = 'santa-barbara_california.osm'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 114
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To get an overview of the data in the osm file, we first count the tag content of the osm data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Problem 6-1 mapparser.py\n",
      "\"\"\"\n",
      "Your task is to use the iterative parsing to process the map file and\n",
      "find out not only what tags are there, but also how many, to get the\n",
      "feeling on how much of which data you can expect to have in the map.\n",
      "The output should be a dictionary with the tag name as the key\n",
      "and number of times this tag can be encountered in the map as value.\n",
      "\n",
      "\"\"\"\n",
      "import xml.etree.ElementTree as ET\n",
      "import pprint\n",
      "\n",
      "def count_tags(filename):\n",
      "    '''\n",
      "    iterparse ET each tag. Check if in tags dictionary. If not, insert key.\n",
      "    '''\n",
      "    tags = {}\n",
      "    for ev,elem in ET.iterparse(filename):\n",
      "        if elem.tag not in tags.keys():\n",
      "            tags[elem.tag] = 1\n",
      "        else:\n",
      "            tags[elem.tag]+=1\n",
      "    return tags\n",
      "\n",
      "tags = count_tags(OSM_FILE)\n",
      "print \"Found tags:\" \n",
      "pprint.pprint(tags)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Found tags:\n",
        "{'bounds': 1,\n",
        " 'member': 4499,\n",
        " 'nd': 922451,\n",
        " 'node': 849371,\n",
        " 'osm': 1,\n",
        " 'relation': 382,\n",
        " 'tag': 302280,\n",
        " 'way': 37789}\n"
       ]
      }
     ],
     "prompt_number": 116
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, we check k-values for each tag to see if we have any k values with problematic characters. \n",
      "We can also see the k:k-type value."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Problem 6-2 tag.py\n",
      "import xml.etree.ElementTree as ET\n",
      "import pprint\n",
      "import re\n",
      "\"\"\"\n",
      "Your task is to explore the data a bit more.\n",
      "Before you process the data and add it into MongoDB, you should\n",
      "check the \"k\" value for each \"<tag>\" and see if they can be valid keys in MongoDB,\n",
      "as well as see if there are any other potential problems.\n",
      "\n",
      "We have provided you with 3 regular expressions to check for certain patterns\n",
      "in the tags. As we saw in the quiz earlier, we would like to change the data model\n",
      "and expand the \"addr:street\" type of keys to a dictionary like this:\n",
      "{\"address\": {\"street\": \"Some value\"}}\n",
      "So, we have to see if we have such tags, and if we have any tags with problematic characters.\n",
      "Please complete the function 'key_type'.\n",
      "\"\"\"\n",
      "lower = re.compile(r'^([a-z]|_)*$')\n",
      "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
      "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
      "lower_colon_vals = {}\n",
      "\n",
      "def key_type(element, keys):\n",
      "    if element.tag == \"tag\":\n",
      "        if lower.search(element.attrib['k']):\n",
      "            keys['lower'] +=1\n",
      "        elif lower_colon.search(element.attrib['k']):\n",
      "            keys['lower_colon']+=1\n",
      "            #record lower colon values\n",
      "            colvals = element.attrib['k'].split(':')\n",
      "            if colvals[0] not in lower_colon_vals.keys():\n",
      "                lower_colon_vals[colvals[0]] = set()\n",
      "            lower_colon_vals[colvals[0]].add(colvals[1])\n",
      "        elif problemchars.search(element.attrib['k']):\n",
      "            keys['problemchars']+=1\n",
      "        else:\n",
      "            keys['other']+=1 \n",
      "    return keys\n",
      "      \n",
      "def process_map(filename):\n",
      "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
      "    for _, element in ET.iterparse(filename):\n",
      "        keys = key_type(element, keys)\n",
      "    return keys\n",
      "\n",
      "keys = process_map(OSM_FILE)\n",
      "print \"Types of k-values and their counts:\"\n",
      "pprint.pprint(keys)\n",
      "print \"Types of colon-separated k-values under lower_colon:\"\n",
      "pprint.pprint(lower_colon_vals)  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Types of k-values and their counts:\n",
        "{'lower': 108936, 'lower_colon': 167516, 'other': 25827, 'problemchars': 1}\n",
        "Types of colon-separated k-values under lower_colon:\n",
        "{'addr': set(['city',\n",
        "              'country',\n",
        "              'county',\n",
        "              'even',\n",
        "              'full',\n",
        "              'housename',\n",
        "              'housenumber',\n",
        "              'odd',\n",
        "              'postcode',\n",
        "              'state',\n",
        "              'street',\n",
        "              'street_direction_prefix',\n",
        "              'unit']),\n",
        " 'alt_name': set(['vi']),\n",
        " 'barrier': set(['personnel', 'security']),\n",
        " 'beacon': set(['colour', 'shape', 'text']),\n",
        " 'bicycle': set(['backward', 'forward']),\n",
        " 'boundary': set(['type']),\n",
        " 'building': set(['color', 'levels', 'material', 'part']),\n",
        " 'buoy': set(['colour', 'shape', 'text']),\n",
        " 'caltrans': set(['district', 'dynsegpm', 'pctuse', 'type']),\n",
        " 'capacity': set(['disabled']),\n",
        " 'census': set(['population']),\n",
        " 'contact': set(['phone']),\n",
        " 'county': set(['abbrev', 'ansi', 'name']),\n",
        " 'crane': set(['type']),\n",
        " 'csp': set(['globalid', 'unitcode']),\n",
        " 'cycleway': set(['right']),\n",
        " 'destination': set(['ref']),\n",
        " 'diet': set(['vegetarian']),\n",
        " 'fog_signal': set(['signal_group', 'signal_period']),\n",
        " 'fuel': set(['biodiesel', 'biogas', 'cng', 'diesel', 'electricity', 'lpg']),\n",
        " 'generator': set(['source']),\n",
        " 'gnis': set(['county_id',\n",
        "              'county_name',\n",
        "              'created',\n",
        "              'edited',\n",
        "              'fcode',\n",
        "              'feature_id',\n",
        "              'feature_type',\n",
        "              'ftype',\n",
        "              'id',\n",
        "              'import_uuid',\n",
        "              'reviewed',\n",
        "              'state_id']),\n",
        " 'hgv': set(['minweight', 'national_network', 'state_network']),\n",
        " 'is_in': set(['continent',\n",
        "               'country',\n",
        "               'country_code',\n",
        "               'county',\n",
        "               'state',\n",
        "               'state_code']),\n",
        " 'leading': set(['angle']),\n",
        " 'light': set(['character',\n",
        "               'colour',\n",
        "               'height',\n",
        "               'range',\n",
        "               'signal_group',\n",
        "               'signal_period',\n",
        "               'signal_sequence']),\n",
        " 'maxspeed': set(['advisory', 'children_present', 'hgv', 'towing', 'trailer']),\n",
        " 'milepost': set(['county']),\n",
        " 'monitoring': set(['water_level']),\n",
        " 'name': set(['ab',\n",
        "              'ace',\n",
        "              'af',\n",
        "              'als',\n",
        "              'am',\n",
        "              'an',\n",
        "              'ang',\n",
        "              'ar',\n",
        "              'arc',\n",
        "              'arz',\n",
        "              'as',\n",
        "              'ast',\n",
        "              'av',\n",
        "              'ay',\n",
        "              'az',\n",
        "              'ba',\n",
        "              'bar',\n",
        "              'bcl',\n",
        "              'be',\n",
        "              'bg',\n",
        "              'bi',\n",
        "              'bm',\n",
        "              'bn',\n",
        "              'bo',\n",
        "              'bpy',\n",
        "              'br',\n",
        "              'bs',\n",
        "              'bxr',\n",
        "              'ca',\n",
        "              'cdo',\n",
        "              'ce',\n",
        "              'ceb',\n",
        "              'chr',\n",
        "              'chy',\n",
        "              'ckb',\n",
        "              'co',\n",
        "              'crh',\n",
        "              'cs',\n",
        "              'csb',\n",
        "              'cu',\n",
        "              'cv',\n",
        "              'cy',\n",
        "              'da',\n",
        "              'de',\n",
        "              'diq',\n",
        "              'dsb',\n",
        "              'dv',\n",
        "              'dz',\n",
        "              'ee',\n",
        "              'el',\n",
        "              'eml',\n",
        "              'en',\n",
        "              'eo',\n",
        "              'es',\n",
        "              'et',\n",
        "              'eu',\n",
        "              'ext',\n",
        "              'fa',\n",
        "              'ff',\n",
        "              'fi',\n",
        "              'fo',\n",
        "              'fr',\n",
        "              'frp',\n",
        "              'frr',\n",
        "              'fur',\n",
        "              'fy',\n",
        "              'ga',\n",
        "              'gag',\n",
        "              'gan',\n",
        "              'gd',\n",
        "              'gl',\n",
        "              'glk',\n",
        "              'gn',\n",
        "              'gu',\n",
        "              'gv',\n",
        "              'ha',\n",
        "              'hak',\n",
        "              'haw',\n",
        "              'he',\n",
        "              'hi',\n",
        "              'hif',\n",
        "              'hr',\n",
        "              'hsb',\n",
        "              'ht',\n",
        "              'hu',\n",
        "              'hy',\n",
        "              'ia',\n",
        "              'id',\n",
        "              'ie',\n",
        "              'ig',\n",
        "              'ik',\n",
        "              'ilo',\n",
        "              'io',\n",
        "              'is',\n",
        "              'it',\n",
        "              'iu',\n",
        "              'ja',\n",
        "              'jbo',\n",
        "              'jv',\n",
        "              'ka',\n",
        "              'kaa',\n",
        "              'kab',\n",
        "              'kbd',\n",
        "              'ki',\n",
        "              'kk',\n",
        "              'kl',\n",
        "              'km',\n",
        "              'kn',\n",
        "              'ko',\n",
        "              'koi',\n",
        "              'krc',\n",
        "              'ks',\n",
        "              'ksh',\n",
        "              'ku',\n",
        "              'kv',\n",
        "              'kw',\n",
        "              'ky',\n",
        "              'la',\n",
        "              'lad',\n",
        "              'lb',\n",
        "              'lbe',\n",
        "              'lez',\n",
        "              'lg',\n",
        "              'li',\n",
        "              'lij',\n",
        "              'lmo',\n",
        "              'ln',\n",
        "              'lo',\n",
        "              'lt',\n",
        "              'ltg',\n",
        "              'lv',\n",
        "              'mdf',\n",
        "              'mg',\n",
        "              'mhr',\n",
        "              'mi',\n",
        "              'min',\n",
        "              'mk',\n",
        "              'ml',\n",
        "              'mn',\n",
        "              'mr',\n",
        "              'mrj',\n",
        "              'ms',\n",
        "              'mt',\n",
        "              'mwl',\n",
        "              'my',\n",
        "              'myv',\n",
        "              'mzn',\n",
        "              'na',\n",
        "              "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "'nah',\n",
        "              'nap',\n",
        "              'nds',\n",
        "              'ne',\n",
        "              'new',\n",
        "              'nl',\n",
        "              'nn',\n",
        "              'no',\n",
        "              'nov',\n",
        "              'nrm',\n",
        "              'nso',\n",
        "              'nv',\n",
        "              'oc',\n",
        "              'om',\n",
        "              'or',\n",
        "              'os',\n",
        "              'pa',\n",
        "              'pag',\n",
        "              'pam',\n",
        "              'pap',\n",
        "              'pcd',\n",
        "              'pdc',\n",
        "              'pfl',\n",
        "              'pih',\n",
        "              'pl',\n",
        "              'pms',\n",
        "              'pnb',\n",
        "              'ps',\n",
        "              'pt',\n",
        "              'qu',\n",
        "              'rm',\n",
        "              'rn',\n",
        "              'ro',\n",
        "              'ru',\n",
        "              'rue',\n",
        "              'rw',\n",
        "              'sa',\n",
        "              'sah',\n",
        "              'sc',\n",
        "              'scn',\n",
        "              'sco',\n",
        "              'sd',\n",
        "              'se',\n",
        "              'sg',\n",
        "              'sh',\n",
        "              'si',\n",
        "              'simple',\n",
        "              'sk',\n",
        "              'sl',\n",
        "              'sm',\n",
        "              'sn',\n",
        "              'so',\n",
        "              'sq',\n",
        "              'sr',\n",
        "              'srn',\n",
        "              'ss',\n",
        "              'stq',\n",
        "              'su',\n",
        "              'sv',\n",
        "              'sw',\n",
        "              'szl',\n",
        "              'ta',\n",
        "              'te',\n",
        "              'tet',\n",
        "              'tg',\n",
        "              'th',\n",
        "              'tk',\n",
        "              'tl',\n",
        "              'tn',\n",
        "              'to',\n",
        "              'tpi',\n",
        "              'tr',\n",
        "              'ts',\n",
        "              'tt',\n",
        "              'tw',\n",
        "              'ty',\n",
        "              'tzl',\n",
        "              'udm',\n",
        "              'ug',\n",
        "              'uk',\n",
        "              'ur',\n",
        "              'uz',\n",
        "              'vec',\n",
        "              'vep',\n",
        "              'vi',\n",
        "              'vls',\n",
        "              'vo',\n",
        "              'wa',\n",
        "              'war',\n",
        "              'wo',\n",
        "              'wuu',\n",
        "              'xal',\n",
        "              'xh',\n",
        "              'xmf',\n",
        "              'yi',\n",
        "              'yo',\n",
        "              'za',\n",
        "              'zea',\n",
        "              'zh',\n",
        "              'zu']),\n",
        " 'nhd': set(['com_id', 'fdate', 'reach_code', 'way_id']),\n",
        " 'nist': set(['fips_code', 'state_fips']),\n",
        " 'note': set(['lanes', 'ref']),\n",
        " 'nps': set(['verified']),\n",
        " 'odbl': set(['note']),\n",
        " 'official_name': set(['vi']),\n",
        " 'old_name': set(['vi']),\n",
        " 'park': set(['type']),\n",
        " 'payment': set(['bitcoin', 'coins']),\n",
        " 'phone': set(['incoming']),\n",
        " 'population': set(['source']),\n",
        " 'public_transport': set(['version']),\n",
        " 'recycling': set(['asphalt', 'concrete', 'oil']),\n",
        " 'ref': set(['fips', 'left', 'right']),\n",
        " 'roof': set(['colour', 'height', 'levels', 'material', 'shape']),\n",
        " 'seamark': set(['information', 'name', 'ref', 'reference', 'status', 'type']),\n",
        " 'short_name': set(['vi']),\n",
        " 'source': set(['bridge',\n",
        "                'cycleway',\n",
        "                'daytime_headlight',\n",
        "                'hgv',\n",
        "                'lanes',\n",
        "                'maxheight',\n",
        "                'maxspeed',\n",
        "                'maxweight',\n",
        "                'name',\n",
        "                'oneway',\n",
        "                'pkey',\n",
        "                'position',\n",
        "                'ref',\n",
        "                'website']),\n",
        " 'source_ref': set(['bridge',\n",
        "                    'cycleway',\n",
        "                    'daytime_headlight',\n",
        "                    'hgv',\n",
        "                    'lanes',\n",
        "                    'maxheight',\n",
        "                    'maxspeed',\n",
        "                    'maxweight',\n",
        "                    'oneway',\n",
        "                    'ref']),\n",
        " 'survey': set(['date']),\n",
        " 'tiger': set(['cfcc',\n",
        "               'county',\n",
        "               'name_base',\n",
        "               'name_direction_prefix',\n",
        "               'name_direction_suffix',\n",
        "               'name_type',\n",
        "               'reviewed',\n",
        "               'separated',\n",
        "               'source',\n",
        "               'tlid',\n",
        "               'upload_uuid',\n",
        "               'zip_left',\n",
        "               'zip_right']),\n",
        " 'toilets': set(['disposal']),\n",
        " 'topmark': set(['colour', 'shape']),\n",
        " 'tower': set(['type']),\n",
        " 'turn': set(['lanes']),\n",
        " 'wikipedia': set(['en'])}\n"
       ]
      }
     ],
     "prompt_number": 117
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can use Linux \"grep\" command to read the osm file. For example,  \n",
      "```\n",
      "cat santa-barbara_california.osm | grep '<tag k=\"tiger'|sort|uniq -c |sort -n\n",
      "```\n",
      "The tiger tag contains information about the TIGER (Topologically Integrated Geographic Encoding and Referencing) inport of USA, which provides detailed geographic information. SEE http://wiki.openstreetmap.org/wiki/TIGER But in this project, I am not going to clean this tag up."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can find the number of unique users"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Problem 6-3 users.py\n",
      "import xml.etree.ElementTree as ET\n",
      "import pprint\n",
      "import re\n",
      "\"\"\"\n",
      "Your task is to explore the data a bit more.\n",
      "The first task is a fun one - find out how many unique users\n",
      "have contributed to the map in this particular area!\n",
      "\n",
      "The function process_map should return a set of unique user IDs (\"uid\")\n",
      "\"\"\"\n",
      "def get_user(element):\n",
      "    return\n",
      "\n",
      "def process_map(filename):\n",
      "    users = set()\n",
      "    for _, element in ET.iterparse(filename):\n",
      "        try:\n",
      "            users.add(element.attrib['uid'])\n",
      "        except KeyError:\n",
      "            continue\n",
      "    return users\n",
      "\n",
      "users = process_map(OSM_FILE)\n",
      "\n",
      "print \"There are %d unique user IDs\" % len(users)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "There are 445 unique user IDs\n"
       ]
      }
     ],
     "prompt_number": 118
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Audit\n",
      "Next, we audit the street types under addr:street tag"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Problem 6-4 audit.py\n",
      "\"\"\"\n",
      "Your task in this exercise has two steps:\n",
      "\n",
      "- audit the OSMFILE and change the variable 'mapping' to reflect the changes needed to fix \n",
      "    the unexpected street types to the appropriate ones in the expected list.\n",
      "    You have to add mappings only for the actual problems you find in this OSMFILE,\n",
      "    not a generalized solution, since that may and will depend on the particular area you are auditing.\n",
      "- write the update_name function, to actually fix the street name.\n",
      "    The function takes a string with street name as an argument and should return the fixed name\n",
      "    We have provided a simple test so that you see what exactly is expected\n",
      "\"\"\"\n",
      "import xml.etree.cElementTree as ET\n",
      "from collections import defaultdict\n",
      "import re\n",
      "import pprint\n",
      "import os\n",
      "\n",
      "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
      "lower = re.compile(r'^([a-z]|_)*$')\n",
      "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')                     \n",
      "# \n",
      "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \"Highway\",\n",
      "            \"Trail\", \"Parkway\", \"Commons\", \"Way\", \"Circle\", \"Plaza\", \"Real\", \"Terrace\", \"Wharf\", \"Alegre\"]\n",
      "\n",
      "# Create a mapping dictionary contained corrected and uncorrected street name, \n",
      "# UPDATE THIS VARIABLE  (gotten from looking at the results of the audit)         \n",
      "\n",
      "mapping = {'E ': 'East ', \n",
      "           'N ': 'North ', 'N. ': 'North ',\n",
      "           'W ': 'West ', 'W. ': 'West ',\n",
      "           'S ': 'South ',  \n",
      "           'Ter.': 'Terrace', 'Ter': 'Terrace',\n",
      "           'Ave': 'Avenue', \n",
      "           'Ctr': 'Circle', 'Ctr.': 'Circle',     \n",
      "           'St.': 'Street', 'St': 'Street', \n",
      "           'Rd': 'Road', 'Rd.': 'Road', \n",
      "           'Blvd.': 'Boulevard', 'Blvd': 'Boulevard', \n",
      "           'Dr': 'Drive',          \n",
      "           'Ln.': 'Lane',  'Ln ': 'Lane', \n",
      "           'Hwy': 'Highway', \n",
      "            }\n",
      "\n",
      "#difference between mapping and changes is we are looking at the entire value in changes and not just the last word. see data.py\n",
      "#changes = { 'N. Fairview': 'North Fairview Avenue',\n",
      "#           'E Meta': 'East Meta Street',\n",
      "#           'Embarcadero Del Norte': 'Embarcadero del Norte',\n",
      "#           '339 W Gonzales Rd': 'West Gonzales Road',\n",
      "#           'Garden Street #201': 'Garden Street',  \n",
      "#            'Garden Streetreet #201' : 'Garden Street', \n",
      "#           'Hwy 33 PM 30.12': 'Highway 33',\n",
      "#            'u'\\u200e3687 Sagunto St':'Sagunto Street',\n",
      "#            'Loma Vista':'Loma Vista Avenue',\n",
      "#           '1722 S Victoria':'South Victoria'}         \n",
      "##skip the full values gotten from looking at the results of the audit that we don't want to include in the database. \n",
      "#Will use in data.py\n",
      "#skip = [\"Jct Of Sr 246 & Sr 154\"]\n",
      "\n",
      "def audit_street_type(street_types, street_name):\n",
      "    '''find the one which are not in expcted name '''\n",
      "    m = street_type_re.search(street_name)\n",
      "    if m:\n",
      "        street_type = m.group()\n",
      "        if street_type not in expected:\n",
      "            street_types[street_type].add(street_name)                      \n",
      "            \n",
      "def is_street_name(elem):\n",
      "    '''find if arrtib k vakue is addr:street'''\n",
      "    return (elem.attrib['k'] == \"addr:street\")\n",
      "\n",
      "def audit(osmfile):\n",
      "    '''Under the addr:street, check name of street to be correct'''\n",
      "    osm_file = open(osmfile, \"r\")\n",
      "    street_types = defaultdict(set)\n",
      "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
      "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
      "            for tag in elem.iter(\"tag\"):\n",
      "                if is_street_name(tag):\n",
      "                    audit_street_type(street_types, tag.attrib['v'])\n",
      "    #elem.clear() #clear from memory\n",
      "    return street_types\n",
      "\n",
      "def update_name(name, mapping):\n",
      "    '''Update each street name with the replacement ending in the mapping dictionary'''\n",
      "    for key in mapping.keys():\n",
      "        if name.find(key)>-1: # if problemtic street name is in the name of street\n",
      "            name=name.replace(key,mapping[key]) # replace problemtic part with value of map dictionary\n",
      "            break       \n",
      "    return name\n",
      "\n",
      "st_types = audit(OSMFILE)\n",
      "pprint.pprint(dict(st_types))\n",
      "print \"--------------\"\n",
      "print \"the corrected street names\"\n",
      "print \"--------------\"\n",
      "for st_type, ways in st_types.iteritems():\n",
      "    for name in ways:\n",
      "        better_name = update_name(name, mapping)\n",
      "        print name, \"=>\", better_name"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'101': set(['North Highway 101']),\n",
        " '154': set(['Highway 154', 'Jct Of Sr 246 & Sr 154']),\n",
        " '201': set(['Garden Street #201']),\n",
        " '246': set(['State Hwy 246']),\n",
        " '30.12': set(['Hwy 33 PM 30.12']),\n",
        " 'Abrego': set(['Abrego']),\n",
        " 'Ave': set(['Lillie Ave',\n",
        "             'Linden Ave',\n",
        "             'Los Angeles Ave',\n",
        "             'N Ashwood Ave',\n",
        "             'N Ventura Ave',\n",
        "             'North Rose Ave',\n",
        "             'Petit Ave',\n",
        "             'Rose Ave',\n",
        "             'S Victoria Ave',\n",
        "             'South Victoria Ave',\n",
        "             'Ventura Ave',\n",
        "             'Vineyard Ave',\n",
        "             'West Ocean Ave']),\n",
        " 'Beach': set(['The Beach']),\n",
        " 'Blvd': set(['E Thompson Blvd', 'Harbor Blvd', 'Thompson Blvd']),\n",
        " 'Blvd.': set(['East Thompson Blvd.']),\n",
        " 'Ciervo': set(['Vereda del Ciervo']),\n",
        " 'Dr': set(['Citrus Dr',\n",
        "            'Daytona Dr',\n",
        "            'Johnson Dr',\n",
        "            'Mathilda Dr',\n",
        "            'Seagull Dr',\n",
        "            'Spinnaker Dr']),\n",
        " 'Fairview': set(['N. Fairview']),\n",
        " 'Hwy': set(['1116 Maricopa Hwy']),\n",
        " 'Lindo': set(['Camino Lindo']),\n",
        " 'Meta': set(['E Meta']),\n",
        " 'Norte': set([' Embarcadero del Norte', 'Embarcadero Del Norte']),\n",
        " 'Playa': set(['Del Playa']),\n",
        " 'Rd': set(['339 W Gonzales Rd',\n",
        "            'Loma Vista Rd',\n",
        "            'Pardall Rd',\n",
        "            'Pasado Rd',\n",
        "            'S Mills Rd',\n",
        "            'Telegraph Rd',\n",
        "            'Telephone Rd',\n",
        "            'Trigo Rd']),\n",
        " 'Rd.': set(['San Ysidro Rd.']),\n",
        " 'Seaward': set(['S Seaward']),\n",
        " 'St': set(['E Main St',\n",
        "            'Garden St',\n",
        "            'Main St',\n",
        "            'Oak St',\n",
        "            'Violeta St',\n",
        "            'W Main St',\n",
        "            u'\\u200e3687 Sagunto St']),\n",
        " 'St.': set(['N. Milpas St.', 'W. Micheltorena St.']),\n",
        " 'Tarde': set(['Sabado Tarde']),\n",
        " 'Trigo': set(['Trigo']),\n",
        " 'Victoria': set(['1722 S Victoria']),\n",
        " 'Vista': set(['Loma Vista'])}\n",
        "--------------\n",
        "the corrected street names\n",
        "--------------\n",
        "Sabado Tarde => Sabado Tarde\n",
        "Loma Vista => Loma Vista\n",
        "Highway 154 => Highway 154\n",
        "Jct Of Sr 246 & Sr 154 => Jct Of Sr 246 & Sr 154\n",
        "S Seaward => South Seaward\n",
        "W. Micheltorena St. => West Micheltorena St.\n",
        "N. Milpas St. => N. Milpas Street\n",
        "Telegraph Rd => Telegraph Road\n",
        "Pardall Rd => Pardall Road\n",
        "Pasado Rd => Pasado Road\n",
        "Telephone Rd => Telephone Road\n",
        "339 W Gonzales Rd => 339 West Gonzales Rd\n",
        "Loma Vista Rd => Loma Vista Road\n",
        "S Mills Rd => S Mills Road\n",
        "Trigo Rd => Trigo Road\n",
        "Del Playa => Del Playa\n",
        "Camino Lindo => Camino Lindo\n",
        "San Ysidro Rd. => San Ysidro Road\n",
        "The Beach => The Beach\n",
        "Hwy 33 PM 30.12 => Highway 33 PM 30.12\n",
        "Trigo => Trigo\n",
        " Embarcadero del Norte =>  Embarcadero del Norte\n",
        "Embarcadero Del Norte => Embarcadero Del Norte\n",
        "1722 S Victoria => 1722 South Victoria\n",
        "N. Fairview => North Fairview\n",
        "1116 Maricopa Hwy => 1116 Maricopa Highway\n",
        "Mathilda Dr => Mathilda Drive\n",
        "Spinnaker Dr => Spinnaker Drive\n",
        "Citrus Dr => Citrus Drive\n",
        "Daytona Dr => Daytona Drive\n",
        "Seagull Dr => Seagull Drive\n",
        "Johnson Dr => Johnson Drive\n",
        "Garden Street #201 => Garden Streetreet #201\n",
        "Abrego => Abrego\n",
        "Garden St => Garden Street\n",
        "Violeta St => Violeta Street\n",
        "Oak St => Oak Street\n",
        "\u200e3687 Sagunto St => \u200e3687 Sagunto Street\n",
        "E Main St => East Main St\n",
        "W Main St => West Main St\n",
        "Main St => Main Street\n",
        "State Hwy 246 => Streetate Hwy 246\n",
        "North Highway 101 => North Highway 101\n",
        "East Thompson Blvd. => East Thompson Boulevard.\n",
        "Vereda del Ciervo => Vereda del Ciervo\n",
        "E Meta => East Meta\n",
        "Thompson Blvd => Thompson Boulevard\n",
        "Harbor Blvd => Harbor Boulevard\n",
        "E Thompson Blvd => East Thompson Blvd\n",
        "Lillie Ave => Lillie Avenue\n",
        "Los Angeles Ave => Los Angeles Avenue\n",
        "Ventura Ave => Ventura Avenue\n",
        "S Victoria Ave => S Victoria Avenue\n",
        "West Ocean Ave => West Ocean Avenue\n",
        "N Ashwood Ave => North Ashwood Ave\n",
        "Rose Ave => Rose Avenue\n",
        "N Ventura Ave => North Ventura Ave\n",
        "South Victoria Ave => South Victoria Avenue\n",
        "Linden Ave => Linden Avenue\n",
        "North Rose Ave => North Rose Avenue\n",
        "Vineyard Ave => Vineyard Avenue\n",
        "Petit Ave => Petit Avenue\n"
       ]
      }
     ],
     "prompt_number": 174
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####data\n",
      "updated, shaped data, and convert osm file to json format."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Problem 6-5 data.py\n",
      "#!/usr/bin/env python\n",
      "# -*- coding: utf-8 -*-\n",
      "import xml.etree.ElementTree as ET\n",
      "import pprint\n",
      "import re\n",
      "import codecs\n",
      "import json\n",
      "import os\n",
      "\"\"\"\n",
      "Wrangle the data and transform the shape of the data\n",
      "into the below model . The output should be a list of dictionaries\n",
      "that look like this:\n",
      "{\n",
      "\"id\": \"2406124091\",\n",
      "\"type: \"node\",\n",
      "\"visible\":\"true\",\n",
      "\"created\": {\n",
      "          \"version\":\"2\",\n",
      "          \"changeset\":\"17206049\",\n",
      "          \"timestamp\":\"2013-08-03T16:43:42Z\",\n",
      "          \"user\":\"linuxUser16\",\n",
      "          \"uid\":\"1219059\"\n",
      "        },\n",
      "\"pos\": [41.9757030, -87.6921867],\n",
      "\"address\": {\n",
      "          \"housenumber\": \"5157\",\n",
      "          \"postcode\": \"60625\",\n",
      "          \"street\": \"North Lincoln Ave\"\n",
      "        },\n",
      "\"amenity\": \"restaurant\",\n",
      "\"cuisine\": \"mexican\",\n",
      "\"name\": \"La Cabana De Don Luis\",\n",
      "\"phone\": \"1 (773)-271-5176\"\n",
      "}\n",
      "\n",
      "\"\"\"\n",
      "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
      "lower = re.compile(r'^([a-z]|_)*$')\n",
      "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
      "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
      "addresschars = re.compile(r'addr:(\\w+)')\n",
      "CREATED = [ \"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n",
      "\n",
      "#skip, changes, and mapping retrieved from looking at the results of audit\n",
      "changes = { 'N. Fairview': 'North Fairview Avenue',\n",
      "           'E Meta': 'East Meta Street',\n",
      "           'Embarcadero Del Norte': 'Embarcadero del Norte',\n",
      "           '339 W Gonzales Rd': 'West Gonzales Road',\n",
      "           'Garden Street #201': 'Garden Street',  \n",
      "            'Garden Streetreet #201' : 'Garden Street', \n",
      "           'Hwy 33 PM 30.12': 'Highway 33',\n",
      "            ''u'\\u200e3687 Sagunto St':'Sagunto Street',\n",
      "            'Loma Vista':'Loma Vista Avenue',\n",
      "           '1722 S Victoria':'South Victoria'}         \n",
      "##skip the full values gotten from looking at the results of the audit that we don't want to include in the database. \n",
      "skip = [\"Jct Of Sr 246 & Sr 154\"]\n",
      "\n",
      "def update_name(name, mapping):\n",
      "    '''Update each street name with the replacement ending in the mapping dictionary'''\n",
      "    for key in mapping.keys():\n",
      "        if name.find(key)>-1: # if problemtic street name is in the name of street\n",
      "            name=name.replace(key,mapping[key]) # replace problemtic part with value of map dictionary\n",
      "            break       \n",
      "    return name\n",
      "\n",
      "def shape_element(element):\n",
      "    \"\"\"Takes a top level element or tag such as way, node, etc and iterates through each element\n",
      "    and 2nd level tag (if applicable). Returns one cleaned\n",
      "    node (could be a 'way' as well) which is a dictionary of all the fields later \n",
      "    to be converted to a JSON document.    \n",
      "    \"\"\"\n",
      "    node = {}\n",
      "    \n",
      "    if element.tag == \"node\" or element.tag == \"way\" : #variable is called node, but it can also be a way\n",
      "        # YOUR CODE HERE\n",
      "        node = {'created':{}, 'type':element.tag}\n",
      "        for k in element.attrib: #iterate through each 1st level attributes of tag 'node' or 'way'\n",
      "            try:\n",
      "                v = element.attrib[k]\n",
      "            except KeyError:\n",
      "                continue\n",
      "            if k == 'lat' or k == 'lon':\n",
      "                continue\n",
      "            if k in CREATED:\n",
      "                node['created'][k] = v\n",
      "            else:\n",
      "                node[k] = v\n",
      "        try:\n",
      "            node['pos']=[float(element.attrib['lat']),float(element.attrib['lon'])]\n",
      "        except KeyError:\n",
      "            pass\n",
      "        \n",
      "        for stag in element.iter('tag'): # iterate through each each 2nd level tag\n",
      "\n",
      "            if v in skip: # it is one of the skipped words founds in the audit\n",
      "                continue\n",
      "            if v in changes: # it is one of the words we need to rename\n",
      "                v = changes[v]\n",
      "            if 'address' not in node.keys():\n",
      "                node['address'] = {}\n",
      "            k = stag.attrib['k']\n",
      "            v = stag.attrib['v']\n",
      "            if k.startswith('addr:'):\n",
      "                if k ==\"addr:street\": # update street name\n",
      "                    v = update_name(v, mapping)\n",
      "                if len(k.split(':')) == 2:\n",
      "                    content = addresschars.search(k)\n",
      "                    if content:\n",
      "                        node['address'][content.group(1)] = v\n",
      "            else:\n",
      "                node[k]=v\n",
      "\n",
      "        if element.tag == \"way\":\n",
      "            node['node_refs'] = []\n",
      "            for nd in element.iter('nd'):\n",
      "                node['node_refs'].append(nd.attrib['ref'])\n",
      "        return node\n",
      "    else:\n",
      "        return None\n",
      "\n",
      "def process_map(file_in, pretty = False):    \n",
      "    # You do not need to change this file\n",
      "    file_out = \"{0}.json\".format(file_in)\n",
      "    data = []\n",
      "    with codecs.open(file_out, \"w\") as fo:        \n",
      "        for _, element in ET.iterparse(file_in):\n",
      "            el = shape_element(element)\n",
      "            if el:\n",
      "                data.append(el)\n",
      "                if pretty:\n",
      "                    fo.write(json.dumps(el, indent=2)+\"\\n\")\n",
      "                else:\n",
      "                    fo.write(json.dumps(el) + \"\\n\")\n",
      "    return data\n",
      "\n",
      "data = process_map(OSM_FILE, False)\n",
      "print \"processed data with {0} records\".format(len(data))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "processed data with 887160 records\n"
       ]
      }
     ],
     "prompt_number": 181
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#check the data format\n",
      "pprint.pprint(data[0:1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[{'created': {'changeset': '5725968',\n",
        "              'timestamp': '2010-09-08T17:17:15Z',\n",
        "              'uid': '82317',\n",
        "              'user': 'AM909',\n",
        "              'version': '3'},\n",
        "  'id': '27139334',\n",
        "  'pos': [34.3548459, -119.3074253],\n",
        "  'type': 'node'}]\n"
       ]
      }
     ],
     "prompt_number": 192
    }
   ],
   "metadata": {}
  }
 ]
}